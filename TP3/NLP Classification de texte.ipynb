{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "825181c9",
   "metadata": {},
   "source": [
    "<h1> GI5 <center> NLP Classification de texte </center><br> By Ammari Youssef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81698e1b",
   "metadata": {},
   "source": [
    "## <font color=red> Chargement du données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ba3a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd6a9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_id</th>\n",
       "      <th>cv_tag</th>\n",
       "      <th>html_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>0</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>1</td>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>2</td>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>3</td>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>4</td>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold_id cv_tag  html_id  sent_id  \\\n",
       "0        0  cv000    29590        0   \n",
       "1        0  cv000    29590        1   \n",
       "2        0  cv000    29590        2   \n",
       "3        0  cv000    29590        3   \n",
       "4        0  cv000    29590        4   \n",
       "\n",
       "                                                text  tag  \n",
       "0  films adapted from comic books have had plenty...  pos  \n",
       "1  for starters , it was created by alan moore ( ...  pos  \n",
       "2  to say moore and campbell thoroughly researche...  pos  \n",
       "3  the book ( or \" graphic novel , \" if you will ...  pos  \n",
       "4  in other words , don't dismiss this film becau...  pos  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"movie_review.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c411d2",
   "metadata": {},
   "source": [
    "## <font color=red> Preprocessing de données textuelles (toLowercase , zero stopwords/punctuation ..etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70748551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Tokenization and lowercasing\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stopwords and punctuation\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Apply pre-processing to the text column\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c3cd14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [films, adapted, comic, books, plenty, success...\n",
       "1    [starters, created, alan, moore, eddie, campbe...\n",
       "2    [say, moore, campbell, thoroughly, researched,...\n",
       "3    [book, graphic, novel, 500, pages, long, inclu...\n",
       "4                       [words, dismiss, film, source]\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da22f3f",
   "metadata": {},
   "source": [
    "## <font color=red> Entrainement du modèle Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f72edf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=df['processed_text'],\n",
    "                 vector_size=100, window=5, min_count=1, sg=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9b176e",
   "metadata": {},
   "source": [
    "## <font color=red> Vectorisation des reviews de movies :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61c5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Vectorize reviews using Word2Vec embeddings\n",
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "\n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "\n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "# Création d'un vocabulaire\n",
    "vocabulary = set(model.wv.index_to_key)\n",
    "\n",
    "# Vectorisation des reviews\n",
    "df['vector'] = df['text'].apply(lambda x: average_word_vectors(word_tokenize(x), model, vocabulary, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c75e2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19379095,  0.50768781,  0.29603772,  0.15621947,  0.03552601,\n",
       "       -0.92494812,  0.196914  ,  0.97582599, -0.27228703, -0.61890008,\n",
       "       -0.07800748, -0.65189194, -0.12398562,  0.308089  ,  0.34736456,\n",
       "       -0.30957173, -0.00586812, -0.40612961, -0.02913243, -1.04193045,\n",
       "        0.32267498,  0.07459503,  0.23368766, -0.14311619, -0.03261911,\n",
       "        0.04751716, -0.26170728, -0.14647747, -0.47522261,  0.07631433,\n",
       "        0.19639288, -0.03694258,  0.03229123, -0.60513341, -0.0257286 ,\n",
       "        0.39964624,  0.22196333, -0.36366683, -0.42888313, -0.64676978,\n",
       "        0.22336517, -0.43486335, -0.14518735,  0.14022401,  0.5016803 ,\n",
       "       -0.28679916, -0.44283414, -0.00607692,  0.19653016,  0.2459543 ,\n",
       "        0.29888651, -0.46299286, -0.48669617, -0.09071458, -0.32579215,\n",
       "        0.07468978,  0.35180817, -0.15028563, -0.2748481 ,  0.11233867,\n",
       "        0.20207276,  0.24658376, -0.1355174 , -0.0211116 , -0.4204115 ,\n",
       "        0.37753133,  0.18743955,  0.47467294, -0.59675974,  0.4820464 ,\n",
       "       -0.25546938,  0.23018683,  0.44862382, -0.15242545,  0.35182172,\n",
       "        0.43186899,  0.01859385, -0.13855949, -0.42159075,  0.38709949,\n",
       "       -0.26091393, -0.02451739, -0.28225951,  0.57565476, -0.11722241,\n",
       "       -0.03200554,  0.06358478,  0.56361313,  0.61464632,  0.20697981,\n",
       "        0.54329307,  0.29565004, -0.04555051,  0.16418108,  0.9273952 ,\n",
       "        0.3270721 ,  0.18975174, -0.44155451,  0.0493456 ,  0.08575125])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vector'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728d0f0",
   "metadata": {},
   "source": [
    "## <font color=red> Division des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e35e87ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Encodage de la variable cible (tag)\n",
    "label_encoder = LabelEncoder()\n",
    "df['tag_encoded'] = label_encoder.fit_transform(df['tag'])\n",
    "\n",
    "# Division des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.vstack(df['vector']), df['tag_encoded'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb5bddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51776, 100)\n",
      "51776\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(len(y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f99fb7",
   "metadata": {},
   "source": [
    "## <font color=red> Construction d'un modéle classificateur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4448677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation du modèle\n",
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7333f7",
   "metadata": {},
   "source": [
    "## <font color=red> Evaluation du modéle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f56b553",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5671353522867738\n",
      "Precision: 0.5682989766460126\n",
      "Recall: 0.5671353522867738\n",
      "F1 Score: 0.5625915815122414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
